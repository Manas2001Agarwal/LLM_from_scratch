{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 256, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        \n",
    "    def forward(self,x):\n",
    "        self.mean = torch.mean(x,dim=-1,keepdim=True)\n",
    "        self.var = torch.var(x,dim=-1,unbiased=False,keepdim=True)\n",
    "        self.shift = nn.Parameter(torch.zeros(x.size()[-1]))\n",
    "        self.scale = nn.Parameter(torch.ones(x.size()[-1]))\n",
    "        norm_x = (x-self.mean)/(self.var+self.eps)\n",
    "        scaled_norm_x = self.scale*norm_x + self.shift\n",
    "        return scaled_norm_x\n",
    "    \n",
    "x = torch.tensor([[1,2],[3,4]])\n",
    "ln = LayerNorm()\n",
    "mean = torch.mean(ln(x.float()),dim=-1)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "        \n",
    "class FeedForward(torch.nn.Module):\n",
    "    def __init__(self,embed_size):\n",
    "        super().__init__()\n",
    "        self.nwt = torch.nn.Sequential(torch.nn.Linear(embed_size,4*embed_size),\n",
    "                   GELU(),\n",
    "                   torch.nn.Linear(4*embed_size,embed_size))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.nwt(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0317,  0.0104,  0.0269,  ..., -0.0217, -0.0332, -0.0078],\n",
      "        [ 0.0092, -0.0069, -0.0194,  ..., -0.0120,  0.0200, -0.0191],\n",
      "        [-0.0184,  0.0054, -0.0235,  ..., -0.0077,  0.0056,  0.0142],\n",
      "        ...,\n",
      "        [-0.0277,  0.0077,  0.0311,  ...,  0.0030, -0.0343,  0.0110],\n",
      "        [-0.0012,  0.0244, -0.0054,  ...,  0.0124,  0.0205, -0.0307],\n",
      "        [-0.0267,  0.0097, -0.0140,  ..., -0.0276, -0.0281,  0.0155]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,768)\n",
    "ff = FeedForward(768)\n",
    "x = ff(x)\n",
    "print(x.shape)\n",
    "print(ff.nwt[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mukulagarwal/Desktop/Projects/transformers/making_LLM_from_scratch/Notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/transformers/making_LLM_from_scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Scripts.mha_attention import MultiHeadAttention\n",
    "class TransformerBlock(torch.nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.ln1 = LayerNorm()\n",
    "        self.ln2 = LayerNorm()\n",
    "        self.ff = FeedForward(cfg['emb_dim'])\n",
    "        self.dropout = torch.nn.Dropout(cfg['drop_rate'])\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out=cfg['emb_dim'],\n",
    "            context_length=cfg['context_length'],\n",
    "            dropout=cfg['drop_rate'],\n",
    "            num_heads=cfg['n_heads'],\n",
    "            qkv_bias=cfg['qkv_bias']\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        shortcut = x\n",
    "        norm_x = self.ln1(x)\n",
    "        mha_x = self.mha(norm_x)\n",
    "        drop_x1 = self.dropout(mha_x)\n",
    "        x = drop_x1 + shortcut\n",
    "        \n",
    "        shortcut = x\n",
    "        norm_x_2 = self.ln2(x)\n",
    "        ff_x = self.ff(norm_x_2)\n",
    "        drop_x2 = self.dropout(ff_x)\n",
    "        x = drop_x2 + shortcut \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,768)\n",
    "trf = TransformerBlock(cfg)\n",
    "x = trf(x)\n",
    "print(x.shape)\n",
    "#print(ff.nwt[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT(torch.nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = torch.nn.Embedding(cfg['vocab_size'],cfg['emb_dim'])\n",
    "        self.positional_embeddings = torch.nn.Embedding(cfg['context_length'],cfg['emb_dim'])\n",
    "        self.dropout = torch.nn.Dropout(cfg['drop_rate'])\n",
    "        self.trf = torch.nn.Sequential(\n",
    "            *[\n",
    "                TransformerBlock(cfg)\n",
    "                for _ in range(cfg['n_layers'])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.final_ln = LayerNorm()\n",
    "        self.out_lin = torch.nn.Linear(cfg['emb_dim'],cfg['vocab_size'])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,seq_length = x.size()\n",
    "        token_embeddings = self.token_embeddings(x)\n",
    "        positional_embeddings = self.positional_embeddings(torch.arange(seq_length))\n",
    "        embeddings = token_embeddings + positional_embeddings\n",
    "        embed_drop = self.dropout(embeddings)\n",
    "        out_trf = self.trf(embed_drop)\n",
    "        norm_out = self.final_ln(out_trf)\n",
    "        logits = self.out_lin(norm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6109,  3626,  6100,   345],\n",
       "        [15496,   616,  1438,   318]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Hello my name is\"\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "txt1_token = torch.tensor(tokenizer.encode(txt1))\n",
    "txt2_token = torch.tensor(tokenizer.encode(txt2))\n",
    "tokens = torch.stack((txt1_token,txt2_token))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3799,  0.5583, -0.0717,  ..., -0.4488,  0.2797, -0.0444],\n",
       "         [ 0.0397,  0.3390, -0.0437,  ..., -0.1328, -0.1661, -0.2715],\n",
       "         [-0.4680, -0.0273, -0.1700,  ...,  0.1494,  0.5256, -0.3046],\n",
       "         [-0.1864, -0.1921, -0.0889,  ...,  0.1119,  0.3309, -0.4785]],\n",
       "\n",
       "        [[-0.3054,  0.4613, -0.0851,  ..., -0.6252,  0.2391,  0.0135],\n",
       "         [ 0.2196, -0.2426,  0.0326,  ...,  0.4261, -0.1267, -0.4724],\n",
       "         [-0.8503, -0.1443, -0.9523,  ...,  0.2352,  0.2361, -0.2981],\n",
       "         [-0.0036, -0.7287, -0.4211,  ..., -0.0189,  0.1912, -0.4896]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPT(cfg)\n",
    "gpt(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162469969"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in gpt.parameters())\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlin_para = sum(p.numel() for p in gpt.out_lin.parameters())\n",
    "total_params = sum(p.numel() for p in gpt.parameters()) - outlin_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4722432\n",
      "2360064\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in trf.ff.parameters()))\n",
    "print(sum(p.numel() for p in trf.mha.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "619.7737464904785"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_params*4)/ (1024*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6109,  3626,  6100,   345, 14042, 32086, 26777, 33848,  4828, 34735,\n",
       "         12604, 18698],\n",
       "        [15496,   616,  1438,   318, 37358,  1330, 25106, 30851, 26559, 20022,\n",
       "         50145, 43669]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_simple_text(model,idx,max_tokens,content_size):\n",
    "    for _ in range(max_tokens):\n",
    "        #idx = idx[:,-content_size:]\n",
    "        logits = model(idx)[:,-1,:]\n",
    "        probas = torch.softmax(logits,dim=-1)\n",
    "        token_id = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "        idx = torch.cat((idx,token_id),dim=1)\n",
    "    return idx\n",
    "\n",
    "idx = generate_simple_text(gpt,tokens,8,256)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is tale awful unfamiliar widation Makoto descriptor Houth\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer.decode(idx[1].tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chapter - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Every Effort moves you coloured Rum soldier verifyingâ–‘ Rather Only Siem cancel antis'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_token_ids(text,tokenizer):\n",
    "    tokens = tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(tokens).unsqueeze(0)   ## Adding Batch Dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids,tokenizer):\n",
    "    token_ids_flat = token_ids.squeeze(0)\n",
    "    text = tokenizer.decode(token_ids_flat.tolist())\n",
    "    return text\n",
    "\n",
    "start_context = \"Every Effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "idx = generate_simple_text(\n",
    "    gpt,\n",
    "    idx = text_to_token_ids(start_context,tokenizer),\n",
    "    max_tokens=10,\n",
    "    content_size=256\n",
    ")\n",
    "\n",
    "token_ids_to_text(idx,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100],\n",
      "        [  40, 1107,  588]])\n",
      "\n",
      "tensor([[ 3626,  6100,  5832],\n",
      "        [ 1107,   588, 11311]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "txt1 = \"Every effort movesyou\"\n",
    "txt2 = \"I really like chocolate\"\n",
    "token_ids_1 = torch.tensor(tokenizer.encode(txt1))\n",
    "token_ids_2 = torch.tensor(tokenizer.encode(txt2))\n",
    "inputs = torch.stack((token_ids_1[:3],token_ids_2[:3]),dim=0)\n",
    "print(inputs)\n",
    "print()\n",
    "targets = torch.stack((token_ids_1[-3:],token_ids_2[-3:]),dim=0)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6109, 3626, 6100],\n",
       "        [  40, 1107,  588]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3626,  6100,  5832],\n",
       "        [ 1107,   588, 11311]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "model = GPT(cfg)\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "    \n",
    "probas = torch.softmax(logits,dim = -1)\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9136],\n",
       "         [ 4374],\n",
       "         [39159]],\n",
       "\n",
       "        [[42019],\n",
       "         [ 2947],\n",
       "         [12854]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_wrd = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "next_wrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' substanceocaljam'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids_to_text(next_wrd[0].flatten(),tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([3.2870e-05, 1.5803e-05, 3.8227e-05])\n",
      "Text 2: tensor([1.5449e-05, 2.8701e-05, 1.8449e-05])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] \n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]] \n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-10.3230, -11.0553, -10.1720, -11.0780, -10.4586, -10.9005])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1,target_probas_2)))\n",
    "log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6645)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_log_loss = -1* torch.mean(log_probas)\n",
    "avg_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits = logits.flatten(start_dim=0,end_dim=1)\n",
    "targets = targets.flatten()\n",
    "print(logits.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 50257])\n",
      "torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9151)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "loss = loss(logits,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/mukulagarwal/Desktop/Projects/transformers/making_LLM_from_scratch/the-verdict.txt\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "train_ratio = int(len(text)*0.90)\n",
    "train_data = text[:train_ratio]\n",
    "val_data = text[train_ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   40,   367,  2885,  1464,  1807,  3619],\n",
      "        [  402,   271, 10899,  2138,   257,  7026]])\n",
      "tensor([[  367,  2885,  1464,  1807,  3619,   402],\n",
      "        [  271, 10899,  2138,   257,  7026, 15632]])\n"
     ]
    }
   ],
   "source": [
    "from Scripts.text_preprocessing import create_dataloader\n",
    "trail_dl = create_dataloader(\n",
    "    text = train_data,\n",
    "    batch_size=2,\n",
    "    maxlength=6,\n",
    "    stride=6\n",
    ")\n",
    "for i, (input_id,target_id) in enumerate(trail_dl):\n",
    "    print(input_id)\n",
    "    print(target_id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from Scripts.text_preprocessing import create_dataloader\n",
    "train_dl = create_dataloader(\n",
    "    text = train_data,\n",
    "    batch_size=2,\n",
    "    maxlength=cfg['context_length'],\n",
    "    stride=cfg['context_length'],\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_dl = create_dataloader(\n",
    "    text = val_data,\n",
    "    batch_size=2,\n",
    "    maxlength=cfg['context_length'],\n",
    "    stride=cfg['context_length'],\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "for i, (input_id,target_id) in enumerate(train_dl):\n",
    "    print(input_id.shape,target_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_batch_loss(input_batch,target_batch,model,device):\n",
    "    input_batch = input_batch.to(device=device)\n",
    "    target_batch = target_batch.to(device=device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "        \n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(start_dim=0,end_dim=1),\n",
    "                                             target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader,model,device,num_batches=None):\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "        \n",
    "    loss_batch = []\n",
    "        \n",
    "    for i, (inputs_id,target_id) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            logits = model(inputs_id)\n",
    "            \n",
    "            loss = torch.nn.functional.cross_entropy(logits.flatten(start_dim=0,end_dim=1),\n",
    "                                             target_id.flatten())\n",
    "            loss_batch.append(loss)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return torch.mean(torch.tensor(loss_batch)).item()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.877686500549316\n",
      "Validation loss: 10.884920120239258\n"
     ]
    }
   ],
   "source": [
    "model = GPT(cfg)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_dl, model, device) \n",
    "    val_loss = calc_loss_loader(val_dl, model, device)\n",
    "    print(\"Training loss:\", train_loss)\n",
    "    print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device)\n",
    "        \n",
    "    model.train()\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_simple_text(start_context,tokenizer,model):\n",
    "    model.eval()\n",
    "    idx = torch.tensor(tokenizer.encode(start_context)).unsqueeze(0)\n",
    "    content_size = 256\n",
    "    output_id = generate_simple_text(model,idx,max_tokens=50,\n",
    "                                     content_size = content_size)\n",
    "    text = token_ids_to_text(output_id,tokenizer)\n",
    "    print(text.replace(\"\\n\",\" \"))   \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "torch.manual_seed(123)\n",
    "def training_gpt(model,train_dl,val_dl,optimizer,device,\n",
    "                 eval_freq,eval_iter,num_epochs,\n",
    "                 start_context = \"Every effort moves\", tokenizer=tokenizer):\n",
    "    track_train_loss,track_val_loss,track_token_count = [],[],[]\n",
    "    tokens_seen,global_step_id = 0, -1\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for input_ids,target_ids in train_dl:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = calc_batch_loss(input_ids,target_ids,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_ids.numel()\n",
    "            global_step_id += 1\n",
    "            \n",
    "            if global_step_id%eval_freq == 0:\n",
    "                train_loss,val_loss = evaluate_model(model,train_dl,val_dl,device,eval_iter)\n",
    "                track_train_loss.append(train_loss)\n",
    "                track_val_loss.append(track_val_loss)\n",
    "                track_token_count.append(tokens_seen)\n",
    "                \n",
    "                print(f\"Ep {epoch+1} (Step {global_step_id:06d}): \"\n",
    "                 f\"Train loss {train_loss:.3f}, \"\n",
    "                 f\"Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        generate_and_print_simple_text(start_context,tokenizer,model)\n",
    "    return track_train_loss,track_val_loss,track_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.392, Val loss 10.480\n",
      "Ep 1 (Step 000005): Train loss 9.539, Val loss 9.842\n",
      "Every effort moves you, the, the, the, the the, the, I had.                                   \n",
      "Ep 2 (Step 000010): Train loss 8.433, Val loss 9.139\n",
      "Ep 2 (Step 000015): Train loss 7.113, Val loss 8.314\n",
      "Every effort moves you know,,,,,,,,,,,.                                     \n",
      "Ep 3 (Step 000020): Train loss 5.347, Val loss 7.328\n",
      "Ep 3 (Step 000025): Train loss 3.710, Val loss 6.546\n",
      "Every effort moves you know the was not that my hostess was \" the of the was of a of the of the was of the was I had to. I was. of his. I had. I was I. the was. \" of the I was his\n",
      "Ep 4 (Step 000030): Train loss 2.482, Val loss 6.341\n",
      "Ep 4 (Step 000035): Train loss 1.568, Val loss 6.273\n",
      "Every effort moves you know; and to me--I glanced after him, so that I. \"There: \"--had, in fact, becoming the man of the moment--as Jack himself, one might put it, had been. \"strong he didn't.\n",
      "Ep 5 (Step 000040): Train loss 1.106, Val loss 6.596\n",
      "Every effort moves you know,\" was one of the ax, his pictures--so handsome, so--so it was no great, in fact, had made him--it was fitting that they should, one might put it, married a rich; and Mrs. Gis\n",
      "Ep 6 (Step 000045): Train loss 0.419, Val loss 6.787\n",
      "Ep 6 (Step 000050): Train loss 0.271, Val loss 7.159\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony.        A slight shade of constraint crossed Mrs. I remember getting off a prodigious phrase about the sketch, married a rich widow, and established himself in\n",
      "Ep 7 (Step 000055): Train loss 0.211, Val loss 7.431\n",
      "Ep 7 (Step 000060): Train loss 0.197, Val loss 7.609\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, when, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture\n",
      "Ep 8 (Step 000065): Train loss 0.138, Val loss 7.753\n",
      "Ep 8 (Step 000070): Train loss 0.122, Val loss 7.788\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, moved aside a _jardiniere_ full of\n",
      "Ep 9 (Step 000075): Train loss 0.138, Val loss 7.945\n",
      "Ep 9 (Step 000080): Train loss 0.087, Val loss 7.821\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.078, Val loss 8.049\n",
      "Every effort moves you?\"     He, his pictures--so handsome, so charming, so disarming, that one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPT(cfg)\n",
    "model.to(device)\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.AdamW(\n",
    "     model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "train_losses, val_losses, tokens_seen= training_gpt(model, train_dl, val_dl, optimizer, device,\n",
    "                                                    eval_freq=5, eval_iter=5,num_epochs=10,\n",
    "                                                    start_context=\"Every effort moves you\", tokenizer=tokenizer )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.048562049865723\n"
     ]
    }
   ],
   "source": [
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simple_text(model,idx,max_tokens,content_size):\n",
    "    for _ in range(max_tokens):\n",
    "        idx = idx[:,-content_size:]\n",
    "        logits = model(idx)[:,-1,:]\n",
    "        probas = torch.softmax(logits,dim=-1)\n",
    "        token_id = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "        idx = torch.cat((idx,token_id),dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you?\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "He, his pictures--so handsome, so charming, so disarming, that one longed\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "ids = generate_simple_text(\n",
    "    model=model,\n",
    "    idx = text_to_token_ids(\"Every effort moves you\",tokenizer=tokenizer),\n",
    "    max_tokens=25,\n",
    "    content_size=cfg['context_length']\n",
    ")\n",
    "print(token_ids_to_text(ids,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hyperparameter configurations: 12960\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "HPARAM_GRID = {\n",
    "    \"batch_size\": [2, 4, 8, 16],\n",
    "    \"drop_rate\": [0.0, 0.1, 0.2],\n",
    "    \"warmup_iters\": [10, 20, 30],\n",
    "    \"weight_decay\": [0.1, 0.01, 0.0],\n",
    "    \"peak_lr\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "    \"initial_lr\": [0.00005, 0.0001],\n",
    "    \"min_lr\": [0.00005, 0.00001, 0.0001],\n",
    "    \"n_epochs\": [5, 10, 15, 20, 25],\n",
    "}\n",
    "\n",
    "hyperparameter_combinations = list(itertools.product(*HPARAM_GRID.values()))\n",
    "total_combinations = len(hyperparameter_combinations)\n",
    "print(f\"Total hyperparameter configurations: {total_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
