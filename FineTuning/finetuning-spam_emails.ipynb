{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1 - Dataset Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mukulagarwal/Desktop/Projects/transformers_/FineTuning'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_Path = \"sms_spam_classification\"\n",
    "data_file_path = Path(extracted_Path) / \"SMSSpamCollection.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip_spam_data(url,zip_path,extracted_path,data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and Extraction\")\n",
    "        return\n",
    "    \n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path,\"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "            \n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "        \n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path,data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_classification/SMSSpamCollection.tsv already exists. Skipping download and Extraction\n"
     ]
    }
   ],
   "source": [
    "download_and_unzip_spam_data(url,zip_path,extracted_Path,data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path,sep = \"\\t\",header = None, names = ['Label','Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here for simplicity we choose to undersample the dataset \n",
    "## to include 747 instances for each class to create a balanced\n",
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df['Label']== \"spam\"].shape[0]\n",
    "    ham_subset = df[df['Label'] == \"ham\"].sample(\n",
    "        num_spam, random_state = 123\n",
    "    )\n",
    "    balanced_df = pd.concat([ham_subset,df[df['Label']==\"spam\"]],axis=0)\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df,train_frac,validation_frac):\n",
    "    df = df.sample(frac=1,random_state=123).reset_index(drop = True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = int(train_end + len(df)*validation_frac)\n",
    "    \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "    \n",
    "    return train_df,validation_df,test_df\n",
    "    \n",
    "train_df,validation_df,test_df = random_split(balanced_df,0.7,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\",index = None)  # type: ignore\n",
    "validation_df.to_csv(\"validation.csv\",index = None) # type: ignore\n",
    "test_df.to_csv(\"test.csv\",index = None) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "## Checking token id for <|endoftext|>\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\",allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Creating DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self,csv_file,tokenizer,max_length = None,\n",
    "                 pad_token = 50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "            \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + (self.max_length - len(encoded_text))*[pad_token]\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index]['Label']\n",
    "        \n",
    "        return (\n",
    "            torch.tensor(encoded,dtype=torch.long),\n",
    "            torch.tensor(label,dtype=torch.long)\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length>max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/transformers_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"FineTuning/train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file = \"FineTuning/validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file = \"FineTuning/test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers=num_workers,\n",
    "    drop_last = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version - torch is : 2.5.1\n",
      "Version - numpy is : 1.26.4\n",
      "Version - transformers is : 4.47.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "for pkg in ['torch','numpy','transformers']:\n",
    "    print(f\"Version - {pkg} is : {version(pkg)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/transformers_/FineTuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd FineTuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2SdpaAttention(\n",
       "        (c_attn): Conv1D(nf=2304, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=768)\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D(nf=3072, nx=768)\n",
       "        (c_proj): Conv1D(nf=768, nx=3072)\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Model\n",
    "\n",
    "model_names = {\n",
    "    \"gpt2-small (124M)\": \"openai-community/gpt2\",\n",
    "    \"gpt2-medium (355M)\": \"openai-community/gpt2-medium\",\n",
    "    \"gpt2-large (774M)\": \"openai-community/gpt2-large\",\n",
    "    \"gpt2-xl (1558M)\": \"openai-community/gpt2-xl\"\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "gpt_hf = GPT2Model.from_pretrained(model_names[CHOOSE_MODEL],cache_dir='checkpoints')\n",
    "gpt_hf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"drop_rate\": 0.0,       # Dropout rate\n",
    "    \"qkv_bias\": True        # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_check(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(right.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights(gpt, gpt_hf):\n",
    "\n",
    "    d = gpt_hf.state_dict()\n",
    "\n",
    "    gpt.pos_emb.weight = assign_check(gpt.pos_emb.weight, d[\"wpe.weight\"])\n",
    "    gpt.tok_emb.weight = assign_check(gpt.tok_emb.weight, d[\"wte.weight\"])\n",
    "    \n",
    "    for b in range(BASE_CONFIG[\"n_layers\"]):\n",
    "        q_w, k_w, v_w = np.split(d[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign_check(gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign_check(gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign_check(gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "    \n",
    "        q_b, k_b, v_b = np.split(d[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign_check(gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign_check(gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign_check(gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "    \n",
    "    \n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign_check(gpt.trf_blocks[b].att.out_proj.weight, d[f\"h.{b}.attn.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign_check(gpt.trf_blocks[b].att.out_proj.bias, d[f\"h.{b}.attn.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign_check(gpt.trf_blocks[b].ff.layers[0].weight, d[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign_check(gpt.trf_blocks[b].ff.layers[0].bias, d[f\"h.{b}.mlp.c_fc.bias\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign_check(gpt.trf_blocks[b].ff.layers[2].weight, d[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign_check(gpt.trf_blocks[b].ff.layers[2].bias, d[f\"h.{b}.mlp.c_proj.bias\"])\n",
    "    \n",
    "        gpt.trf_blocks[b].norm1.scale = assign_check(gpt.trf_blocks[b].norm1.scale, d[f\"h.{b}.ln_1.weight\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign_check(gpt.trf_blocks[b].norm1.shift, d[f\"h.{b}.ln_1.bias\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign_check(gpt.trf_blocks[b].norm2.scale, d[f\"h.{b}.ln_2.weight\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign_check(gpt.trf_blocks[b].norm2.shift, d[f\"h.{b}.ln_2.bias\"])\n",
    "    \n",
    "        gpt.final_norm.scale = assign_check(gpt.final_norm.scale, d[f\"ln_f.weight\"])\n",
    "        gpt.final_norm.shift = assign_check(gpt.final_norm.shift, d[f\"ln_f.bias\"])\n",
    "        gpt.out_head.weight = assign_check(gpt.out_head.weight, d[\"wte.weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/transformers_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%pwd\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "from making_LLM_from_scratch.Scripts.gpt_archietecture import GPTModel\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(gpt, gpt_hf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the model by doing next word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a disco dancer, and I love to dance. I love to dance. I love to dance. I love to dance. I love to dance. I love to\n"
     ]
    }
   ],
   "source": [
    "input_prompt = \"I am a disco dancer\"\n",
    "from making_LLM_from_scratch.Scripts.training_gpt import generate_simple_text,text_to_token_ids,token_ids_to_text\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "torch.manual_seed(123)\n",
    "\n",
    "idx = generate_simple_text(\n",
    "    model = gpt.to(device),\n",
    "    idx = text_to_token_ids(input_prompt,\n",
    "                            tokenizer=tokenizer).to(device),\n",
    "    max_tokens = 30,\n",
    "    content_size = BASE_CONFIG['context_length']\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(idx,tokenizer=tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding a Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in gpt.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "gpt.out_head = torch.nn.Linear(\n",
    "    BASE_CONFIG['emb_dim'],\n",
    "    num_classes\n",
    ")\n",
    "\n",
    "for param in gpt.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in gpt.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"Do you have time\"\n",
    "input_tokens = torch.tensor(tokenizer.encode(input)).unsqueeze(0)\n",
    "response = gpt(input_tokens)\n",
    "pred_class_label = torch.argmax(torch.softmax(response[:,-1,:],dim=-1),dim=-1,keepdim=True).item()\n",
    "pred_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5211,  345,  423,  640]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(dataloader,model,device,num_batches=None):\n",
    "    model.eval() \n",
    "    accuracy,total_datapoint = 0,0\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if num_batches==None:\n",
    "         num_batches = len(dataloader)\n",
    "         \n",
    "    if num_batches<len(dataloader):\n",
    "         num_batches = min(num_batches,len(dataloader))\n",
    "         \n",
    "    for i, (input_tokens,label) in enumerate(dataloader):\n",
    "         if i < num_batches:  \n",
    "               input_tokens = input_tokens.to(device)\n",
    "               label = label.to(device)\n",
    "               with torch.no_grad():\n",
    "                    logits = model(input_tokens)\n",
    "               probas = torch.softmax(logits[:,-1,:],dim=-1)\n",
    "               pred_class_label = torch.argmax(probas,dim=-1,keepdim=True)\n",
    "               accuracy_per_batch = torch.sum((pred_class_label.squeeze()==label).float()).item()\n",
    "               \n",
    "               accuracy += accuracy_per_batch\n",
    "               total_datapoint += len(label)\n",
    "         else:\n",
    "              break\n",
    "         \n",
    "    model.train()\n",
    "         \n",
    "    return accuracy/total_datapoint\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475\n",
      "0.45\n",
      "0.4875\n"
     ]
    }
   ],
   "source": [
    "#x,y =next(iter(val_loader))\n",
    "device = torch.device(\"cpu\")\n",
    "print(calc_accuracy_loader(train_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(val_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(test_loader,gpt,device,num_batches=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_tokens,label,model,device):\n",
    "    \n",
    "    input_tokens = input_tokens.to(device)\n",
    "    label = label.to(device)\n",
    "    \n",
    "    logits = model(input_tokens)[:,-1,:]\n",
    "    \n",
    "    loss = torch.nn.functional.cross_entropy(logits,label)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(dataloader,model,device,num_batches):\n",
    "    model.eval() \n",
    "    total_loss = 0\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if len(dataloader) == 0:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    if num_batches==None:\n",
    "         num_batches = len(dataloader)\n",
    "         \n",
    "    if num_batches<len(dataloader):\n",
    "         num_batches = min(num_batches,len(dataloader))\n",
    "          \n",
    "    for i , (input_tokens,label) in enumerate(dataloader):\n",
    "        if i<num_batches:\n",
    "            loss= calc_loss_batch(input_tokens,label,model,device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3219622373580933"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_loss_loader(test_loader,gpt,device,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model,train_loader,val_loader,device,eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader,model,device,num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader,model,device,num_batches=eval_iter)\n",
    "        \n",
    "    model.train()\n",
    "    return train_loss,val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spam_classifier(model,train_dataloader,val_dataloader,num_epochs,optimizer,\n",
    "                          device,eval_freq,eval_iter):\n",
    "    \n",
    "    train_losses,validation_losses,track_samples_seen = [],[],[]\n",
    "    train_acccuracies, val_accuracies = [],[]\n",
    "    samples_seen,global_step = 0,-1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for j, (input_tokens,label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_tokens,label,model,device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            samples_seen += len(label)\n",
    "            track_samples_seen.append(samples_seen)\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step%eval_freq==0:\n",
    "                train_loss,val_loss = evaluate_model(model,train_dataloader,val_dataloader,\n",
    "                                                     device,eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                validation_losses.append(val_loss)\n",
    "                \n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                 f\"Train loss {train_loss:.3f}, \"\n",
    "                 f\"Val loss {val_loss:.3f}\")\n",
    "                \n",
    "        train_accu = calc_accuracy_loader(train_dataloader,model,device)\n",
    "        val_accu = calc_accuracy_loader(val_dataloader,model,device)\n",
    "        \n",
    "        train_acccuracies.append(train_accu)\n",
    "        val_accuracies.append(val_accu)\n",
    "        \n",
    "    return train_losses,validation_losses,train_acccuracies,val_accuracies,track_samples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.034, Val loss 2.545\n",
      "Ep 1 (Step 000050): Train loss 0.917, Val loss 0.824\n",
      "Ep 1 (Step 000100): Train loss 0.669, Val loss 0.701\n",
      "Ep 2 (Step 000150): Train loss 0.656, Val loss 0.662\n",
      "Ep 2 (Step 000200): Train loss 0.626, Val loss 0.641\n",
      "Ep 2 (Step 000250): Train loss 0.663, Val loss 0.630\n",
      "Ep 3 (Step 000300): Train loss 0.622, Val loss 0.599\n",
      "Ep 3 (Step 000350): Train loss 0.571, Val loss 0.571\n",
      "Ep 4 (Step 000400): Train loss 0.552, Val loss 0.551\n",
      "Ep 4 (Step 000450): Train loss 0.551, Val loss 0.531\n",
      "Ep 4 (Step 000500): Train loss 0.531, Val loss 0.510\n",
      "Ep 5 (Step 000550): Train loss 0.543, Val loss 0.503\n",
      "Ep 5 (Step 000600): Train loss 0.496, Val loss 0.470\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(gpt.parameters(),lr = 1e-5,weight_decay=0.1)\n",
    "\n",
    "train_losses,validation_losses,train_acccuracies,val_accuracies,track_samples_seen = train_spam_classifier(\n",
    "    gpt,train_loader,val_loader,5,optimizer,device,50,5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mukulagarwal/Desktop/Projects/transformers_/FineTuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen,train_losses, val_losses,figure_name):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(figure_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, 5, len(train_losses))\n",
    "plot_losses(epochs_tensor, train_losses, validation_losses,\"gpt-small-fintuned.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text,model,tokenizer,max_length = None,pad_token_id = 50256):\n",
    "    \n",
    "    input_tokens = tokenizer.encode(text)\n",
    "    sup_context_length = model.pos_emb.weight.shape[0]\n",
    "    input_ids = input_tokens[:min(max_length,sup_context_length)]\n",
    "    \n",
    "    input_ids += [pad_token_id]*(max_length-len(input_ids))\n",
    "    input_ids = torch.tensor(input_ids,device=device).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids)[:,-1,:]\n",
    "        \n",
    "    predicted_labels = torch.argmax(logits,dim=-1,keepdim=True).item()\n",
    "    return \"spam\" if predicted_labels == 1 else \"not spam\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    classify_review(text_2,gpt,tokenizer,max_length=train_dataset.max_length)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading saved GPT-small FineTunes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "        \"vocab_size\": 50257,     # Vocabulary size\n",
    "        \"context_length\": 1024,  # Context length\n",
    "        \"emb_dim\": 768,          # Embedding dimension\n",
    "        \"n_heads\": 12,           # Number of attention heads\n",
    "        \"n_layers\": 12,          # Number of layers\n",
    "        \"drop_rate\": 0.1,        # Dropout rate\n",
    "        \"qkv_bias\": True         # Query-key-value bias\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=GPT_CONFIG_124M[\"emb_dim\"], out_features=num_classes)\n",
    "\n",
    "model_path = \"/Users/mukulagarwal/Desktop/Projects/transformers_/FineTuning/review_classifier.pth\"\n",
    "\n",
    "# Then load model weights\n",
    "checkpoint = torch.load(model_path, map_location=device, weights_only=True)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8298076923076924\n",
      "0.8456375838926175\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy_loader(train_loader,model,device))\n",
    "print(calc_accuracy_loader(val_loader,model,device))\n",
    "print(calc_accuracy_loader(test_loader,model,device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LORA Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self,in_dim,out_dim,rank,alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim,rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A,a=math.sqrt(5))\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank,out_dim))\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self,X):\n",
    "        x = self.alpha * (X @ self.A @ self.B) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self,linear,rank,alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(linear.in_features,linear.out_features,rank,alpha)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model,rank,alpha):\n",
    "    for name,module in model.named_children():\n",
    "        if isinstance(module,torch.nn.Linear):\n",
    "            setattr(model,name,LinearWithLoRA(module,rank,alpha))\n",
    "        else:\n",
    "            replace_linear_with_lora(module,rank,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from making_LLM_from_scratch.Scripts.gpt_archietecture import GPTModel\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights(gpt, gpt_hf)\n",
    "\n",
    "for param in gpt.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "gpt.out_head = torch.nn.Linear(\n",
    "    BASE_CONFIG['emb_dim'],\n",
    "    num_classes\n",
    ")\n",
    "\n",
    "for param in gpt.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "for param in gpt.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameters:  7090946\n"
     ]
    }
   ],
   "source": [
    "total_model_parameter = sum(p.numel() for p in gpt.parameters() if p.requires_grad == True)\n",
    "print(\"Total Model Parameters: \",total_model_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameters After:  0\n"
     ]
    }
   ],
   "source": [
    "for param in gpt.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "total_model_parameter = sum(p.numel() for p in gpt.parameters() if p.requires_grad == True)\n",
    "print(\"Total Model Parameters After: \",total_model_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Parameters:  2666528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(gpt,rank=16,alpha=16)\n",
    "total_model_parameter = sum(p.numel() for p in gpt.parameters() if p.requires_grad == True)\n",
    "print(\"Total Trainable Parameters: \",total_model_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "devive = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device)\n",
    "print(gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475\n",
      "0.45\n",
      "0.4875\n"
     ]
    }
   ],
   "source": [
    "#x,y =next(iter(val_loader))\n",
    "device = torch.device(\"cpu\")\n",
    "print(calc_accuracy_loader(train_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(val_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(test_loader,gpt,device,num_batches=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.955, Val loss 0.832\n",
      "Ep 1 (Step 000050): Train loss 0.433, Val loss 0.382\n",
      "Ep 1 (Step 000100): Train loss 0.411, Val loss 0.313\n",
      "Ep 2 (Step 000150): Train loss 0.445, Val loss 0.336\n",
      "Ep 2 (Step 000200): Train loss 0.307, Val loss 0.215\n",
      "Ep 2 (Step 000250): Train loss 0.538, Val loss 0.658\n",
      "Ep 3 (Step 000300): Train loss 0.341, Val loss 0.540\n",
      "Ep 3 (Step 000350): Train loss 0.160, Val loss 0.055\n",
      "Ep 4 (Step 000400): Train loss 0.133, Val loss 0.045\n",
      "Ep 4 (Step 000450): Train loss 0.142, Val loss 0.035\n",
      "Ep 4 (Step 000500): Train loss 0.079, Val loss 0.195\n",
      "Ep 5 (Step 000550): Train loss 0.061, Val loss 0.086\n",
      "Ep 5 (Step 000600): Train loss 0.058, Val loss 0.212\n",
      "total_time:  {24.12}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(gpt.parameters(),lr = 1e-5,weight_decay=0.1)\n",
    "start_time = time.time()\n",
    "\n",
    "train_losses,validation_losses,train_acccuracies,val_accuracies,track_samples_seen = train_spam_classifier(\n",
    "    gpt,train_loader,val_loader,5,optimizer,device,50,5\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"total_time: \", {round((end_time-start_time)/60,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, 5, len(train_losses))\n",
    "plot_losses(epochs_tensor, train_losses, validation_losses,'lora-finedtuned-gpt-small.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625\n",
      "0.975\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "print(calc_accuracy_loader(train_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(val_loader,gpt,device,num_batches=10))\n",
    "print(calc_accuracy_loader(test_loader,gpt,device,num_batches=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch/lib/python3.12/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'FineTuning'\n",
      "/Users/mukulagarwal/Desktop/Projects/transformers_/FineTuning\n"
     ]
    }
   ],
   "source": [
    "%cd FineTuning\n",
    "torch.save(gpt.state_dict(),\"lora_spam_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistillBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=2\n",
    "    )\n",
    "\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=2)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.pre_classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.distilbert.transformer.layer[-1].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"validation.csv\")\n",
    "\n",
    "X_train = list(train_df['Text'])\n",
    "y_train = list(train_df['Label'])\n",
    "\n",
    "X_val = list(val_df['Text'])\n",
    "y_val = list(val_df['Label'])\n",
    "\n",
    "X_train_tokenized = tokenizer(X_train,truncation=True,max_length=256,padding=True)\n",
    "X_val_tokenized = tokenizer(X_val,truncation=True,max_length=256,padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  2572,  2006,  1037,  3345,  2067,  2013, 15944,  2061,  1045,\n",
       "          1005,  1049,  4452,  2025,   999,  1045,  1005,  1049,  6595,  3712,\n",
       "          6455,  2125,  2651,  7570,  7570,   999,  2097,  2022,  2105,  9317,\n",
       "          2295,  1012,  2079,  2017, 11281,  1996,  4038,  2252,  2023,  2733,\n",
       "          2011,  1996,  2126,  1029,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "def compute_metrics(p):\n",
    "    print(type(p))\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    return {\"accuracy\":accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"distillbert-output\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8\n",
    "\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/655 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      " 76%|  | 500/655 [01:15<00:21,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0828, 'grad_norm': 0.015849823132157326, 'learning_rate': 1.1832061068702292e-05, 'epoch': 3.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 655/655 [01:37<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 97.2673, 'train_samples_per_second': 53.718, 'train_steps_per_second': 6.734, 'train_loss': 0.06800387324267672, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=655, training_loss=0.06800387324267672, metrics={'train_runtime': 97.2673, 'train_samples_per_second': 53.718, 'train_steps_per_second': 6.734, 'total_flos': 168986046075000.0, 'train_loss': 0.06800387324267672, 'epoch': 5.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38it [00:37,  1.01it/s]                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.trainer_utils.EvalPrediction'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.030464831739664078,\n",
       " 'eval_accuracy': 0.9865771812080537,\n",
       " 'eval_runtime': 1.33,\n",
       " 'eval_samples_per_second': 112.031,\n",
       " 'eval_steps_per_second': 14.286,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distillbert-model-fined-tuned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pretrained Distill-Bert Model and testing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distillbert-model-fined-tuned were not used when initializing DistilBertForSequenceClassification: ['out_head.bias', 'out_head.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9867541e-01, 1.3246136e-03],\n",
       "       [8.5922057e-04, 9.9914074e-01]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = AutoModelForSequenceClassification.from_pretrained(\"distillbert-model-fined-tuned\")\n",
    "text = [\"I Love you baby, will meet you tommorow at the cafe\",\"You have won a lottery. Click on this link and fill the form to claim your prize\"]\n",
    "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt')\n",
    "outputs = model_2(**inputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
